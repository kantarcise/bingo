{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big O - Time and Space Tradeoff\n",
    "\n",
    "We are interested in the design of ‚Äú**good**‚Äù data structures and algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why?\n",
    "\n",
    "Because experimental analysis is hard to make a baseline. Software and Hardware changes.\n",
    "\n",
    "Cannot really stretch the inputs size.\n",
    "\n",
    "Need full implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Is there something independent of OS, takes into account of all possible inputs and with a high level description (without the need of implementation) ?\n",
    "\n",
    "#### Counting Primitive Operations\n",
    "\n",
    "To analyze the running time of an algorithm without performing experiments, we perform an analysis directly on a high-level description of the algorithm (either in the form of an actual code fragment, or language-independent pseudo-code). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring Operations as a Function of Input Size ü§î\n",
    "\n",
    "To capture the order of growth of an algorithm‚Äôs running time, we will associate,  with each algorithm, a function $f(n)$ that **characterizes the number of primitive operations** that are performed as a function of the input size $n$.\n",
    "\n",
    "So the $f(n)$ is to **characterize the number of primitive operations**. \n",
    "#### Focusing on the Worst Case Input\n",
    "\n",
    "An algorithm may run faster on some inputs than it does on others of the same size. Thus, we may wish to express the running time of an algorithm as the function of the input size obtained by taking the average over all possible inputs of the same size. Unfortunately, such an average-case analysis is typically quite challenging.\n",
    "\n",
    "Worst-case analysis is much easier than average-case analysis, as it requires only the ability to identify the worst-case input, which is often simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seven Functions - `the 7` üòâ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Constant Function - $f(n) = c$\n",
    "\n",
    "For any argument $n$, the constant function $f(n)$ assigns the value $c$. In other words, it does not matter what the value of n is; $f(n)$ will always be equal to the constant value c.\n",
    "$$f(n) = c$$\n",
    "\n",
    "```python\n",
    "a = 9\n",
    "my_str = \"e\"\n",
    "print(len([1,2,3]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Logarithm Function - $log_b(n)$ \n",
    "\n",
    "One of the interesting and sometimes even surprising aspects of the analysis of data structures and algorithms is the ubiquitous presence of the logarithm function, \n",
    "$$f(n) = log_b(n)\n",
    "\n",
    "$$ for some constant $b > 1$. \n",
    "\n",
    "This function is defined as follows: $$x = log_b(n)$$ if and only if $$b^x = n$$\n",
    "```python\n",
    "def binary_search(collection: list, target: int) -> int:\n",
    "\t\"\"\"Return the index of a target number in \n",
    "\tnon decreasing collection. If target is not in the\n",
    "\tcollection, return -1\"\"\"\n",
    "\tlow, high = 0, len(collection) - 1\n",
    "\twhile low <= high:\n",
    "\t\tmiddle = low + ((high - low) // 2)\n",
    "\t\tif target == collection[middle]:\n",
    "\t\t\treturn middle\n",
    "\t\telif target < collection[middle]:\n",
    "\t\t\thigh = middle - 1\n",
    "\t\telse:\n",
    "\t\t\tlow = middle + 1\n",
    "\treturn -1\n",
    "```\n",
    "\n",
    "By definition, $log_b(1) = 0$. The value $b$ is known as the base of the logarithm.\n",
    "\n",
    "Here are some properties about $log$:\n",
    "\n",
    "Given real numbers $a > 0,  b > 1,  c > 0, d > 1$ , we have:\n",
    "\n",
    "1. $log_b(ac) = log_b(a) + log_b(c)$\n",
    "2. $log_b(a/c) = log_b(a) ‚àí log_b(c)$\n",
    "3. $log_b(a^c) = c * log_b(a)$\n",
    "4. $log_b a = log_d(a)/ log_d(b)$\n",
    "5. $b^{log_d(a)} = a^{log_d(b)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Linear Function üòç - $f(n) = n$\n",
    "\n",
    "Another simple yet important function is the linear function,\n",
    "$$f(n) = n$$\n",
    "\n",
    "That is, given an input value $n$, the linear function $f$ assigns the value $n$ itself.\n",
    "\n",
    "This function arises in algorithm analysis any time we have to do a single basic operation for each of $n$ elements. \n",
    "\n",
    "For example, comparing a number $x$ to each element of a sequence of size $n$ will require $n$ comparisons.\n",
    "\n",
    "```python\n",
    "seq = [\"1\", \"5\", \"9\"]\n",
    "x = 4\n",
    "for elem in seq:\n",
    "\tif (int(elem) > x) and elem.isprintable():\n",
    "\t\tprint(elem)\n",
    "\n",
    "# also just making a list is o(n) too\n",
    "my_list = [\"w\", \"w\", \"l\", \"w\", \"l\", \"l\"]\n",
    "```\n",
    "\n",
    "The linear function also represents the best running time we can hope to achieve for any algorithm that processes each of n objects that are not already in the computer‚Äôs memory, because reading in the n objects already requires n operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The N-Log-N Function - `sorted(iterable)` or `my_list.sort()`\n",
    "\n",
    "The function that assigns to an input $n$ the value of $n$ times the logarithm base-two of $n$. \n",
    "$$f(n) = n * log(n)$$\n",
    "\n",
    "This function grows a **little more rapidly** than the linear function and **a lot less rapidly** than the quadratic function; therefore, we would ==greatly prefer== an algorithm with a running time that is proportional to $n*log (n)$, than one with quadratic running time.\n",
    "\n",
    "```python\n",
    "from heapq import heapify, heappop\n",
    "def heap_sort(seq):\n",
    "\theapify(seq)\n",
    "\tres = []\n",
    "\twhile seq:\n",
    "\t\tres.append(heappop(seq))\n",
    "\treturn res\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Quadratic Function üòï\n",
    "\n",
    "Given an input value $n$, the function f assigns the product of $n$ with itself (in other words, ‚Äún squared‚Äù).\n",
    "$$f(n) = n ^ 2$$\n",
    "\n",
    "```python\n",
    "rows = 5\n",
    "# outer loop\n",
    "for i in range(1, rows + 1):\n",
    "\t# inner loop\n",
    "\tfor j in range(1, i + 1):\n",
    "\t\tprint(\"*\", end=\" \")\n",
    "\tprint('')\n",
    "# * \n",
    "# * * \n",
    "# * * * \n",
    "# * * * * \n",
    "# * * * * *\n",
    "```\n",
    "\n",
    "The main reason why the quadratic function appears in the analysis of algorithms is that there are many algorithms that have nested loops, where the inner loop performs a linear number of operations and the outer loop is performed a linear number of times. \n",
    "\n",
    "Thus, in such cases, the algorithm performs $n * n = n^2$ operations.\n",
    "\n",
    "The quadratic function can also arise in the context of nested loops where the first iteration of a loop uses one operation, the second uses two operations, the third uses three operations, and so on. That is, the number of operations is $$1 + 2 + 3 + ¬∑ ¬∑ ¬∑ + (n ‚àí 2) + (n ‚àí 1) + n = \\frac{n * (n-1)}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Cubic Function and Other Polynomials üòÆ\n",
    "\n",
    "Continuing our discussion of functions that are powers of the input, we consider the cubic function,$$f(n) = n^3$$ which assigns to an input value $n$ the product of $n$ with itself three times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Exponential Function  üò¶\n",
    "\n",
    "Another function used in the analysis of algorithms is the exponential function,\n",
    "\n",
    "$$f(n) = b^n$$\n",
    "\n",
    "where $b$ is a positive constant, called the base, and the argument $n$ is the exponent. That is, function $f(n)$ assigns to the input argument $n$ the value obtained by multiplying the base $b$ by itself $n$ times.\n",
    "\n",
    "If we have a loop that starts by performing one operation and then doubles the number of operations performed with each iteration, then the number of operations performed in the `nth` iteration is $2^n$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We generally use better data structures in our solutions to improve runtime.\n",
    "\n",
    "- We can use different tecniques to simply and/or improve the solutions, greedy or Dynamic Programming.\n",
    "\n",
    "- 1D-DP is a classic way to get to O(n) time complexity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
